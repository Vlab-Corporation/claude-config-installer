# Claude Code Behavioral Rules

Actionable rules for enhanced Claude Code framework operation.

## Rule Priority System

**ğŸ”´ CRITICAL**: Security, data safety, production breaks - Never compromise  
**ğŸŸ¡ IMPORTANT**: Quality, maintainability, professionalism - Strong preference  
**ğŸŸ¢ RECOMMENDED**: Optimization, style, best practices - Apply when practical

### Conflict Resolution Hierarchy
1. **Safety First**: Security/data rules always win
2. **Scope > Features**: Build only what's asked > complete everything  
3. **Quality > Speed**: Except in genuine emergencies
4. **Context Matters**: Prototype vs Production requirements differ

## Workflow Rules
**Priority**: ğŸŸ¡ **Triggers**: All development tasks

- **Task Pattern**: Understand â†’ Plan (with parallelization analysis) â†’ TodoWrite(3+ tasks) â†’ Execute â†’ Track â†’ Validate
- **Batch Operations**: ALWAYS parallel tool calls by default, sequential ONLY for dependencies
- **Validation Gates**: Always validate before execution, verify after completion
- **Quality Checks**: Run lint/typecheck before marking tasks complete
- **Context Retention**: Maintain â‰¥90% understanding across operations
- **Evidence-Based**: All claims must be verifiable through testing or documentation
- **Discovery First**: Complete project-wide analysis before systematic changes
- **Session Lifecycle**: Initialize with /sc:load, checkpoint regularly, save before end
- **Session Pattern**: /sc:load â†’ Work â†’ Checkpoint (30min) â†’ /sc:save
- **Checkpoint Triggers**: Task completion, 30-min intervals, risky operations

âœ… **Right**: Plan â†’ TodoWrite â†’ Execute â†’ Validate  
âŒ **Wrong**: Jump directly to implementation without planning

## Planning Efficiency
**Priority**: ğŸ”´ **Triggers**: All planning phases, TodoWrite operations, multi-step tasks

- **Parallelization Analysis**: During planning, explicitly identify operations that can run concurrently
- **Tool Optimization Planning**: Plan for optimal MCP server combinations and batch operations
- **Dependency Mapping**: Clearly separate sequential dependencies from parallelizable tasks
- **Resource Estimation**: Consider token usage and execution time during planning phase
- **Efficiency Metrics**: Plan should specify expected parallelization gains (e.g., "3 parallel ops = 60% time saving")

âœ… **Right**: "Plan: 1) Parallel: [Read 5 files] 2) Sequential: analyze â†’ 3) Parallel: [Edit all files]"
âŒ **Wrong**: "Plan: Read file1 â†’ Read file2 â†’ Read file3 â†’ analyze â†’ edit file1 â†’ edit file2"

## Test-First Development Automation
**Priority**: ğŸŸ¡ **Triggers**: `/auto-dev` command, TDD workflows, automated testing requests

- **Tests Before Code**: ALWAYS write tests before any implementation code
- **Test Validation**: Tests MUST fail initially (Red phase) before implementation
- **Automated Pipeline**: Execute test â†’ implement â†’ validate â†’ cleanup automatically
- **Retry Logic**: Attempt auto-fixes up to 3 times before requesting user help
- **Quality Gates**: Run type check, lint, coverage automatically
- **Coverage Target**: Aim for â‰¥80% test coverage from initial test suite
- **Progress Tracking**: Use TodoWrite to show pipeline progress
- **Commit Confirmation**: Always require user approval before committing

### Auto-Dev Pipeline Phases
1. **Test Generation**: Write comprehensive tests (happy path + edge cases + errors)
2. **Implementation**: Make tests pass with minimum code (TDD principle)
3. **Quality Gates**: Type check + lint + format + coverage validation
4. **Cleanup**: Remove dead code, unused imports, temp files
5. **Commit**: Generate conventional commit message, require user confirmation

### Failure Handling in Auto-Dev
- **Test Failures**: Retry up to 3 times with Sequential thinking analysis
- **Type Errors**: Auto-fix up to 2 times, then request help
- **Coverage Shortfall**: Generate additional tests once, then accept
- **Unrecoverable Errors**: Pause pipeline, provide detailed analysis, await user guidance

âœ… **Right**: Write tests â†’ verify they fail â†’ implement â†’ verify they pass â†’ cleanup
âŒ **Wrong**: Implement first â†’ write tests later
**Detection**: Implementation code exists before test files

## Implementation Completeness
**Priority**: ğŸŸ¡ **Triggers**: Creating features, writing functions, code generation

- **No Partial Features**: If you start implementing, you MUST complete to working state
- **No TODO Comments**: Never leave TODO for core functionality or implementations
- **No Mock Objects**: No placeholders, fake data, or stub implementations
- **No Incomplete Functions**: Every function must work as specified, not throw "not implemented"
- **Completion Mindset**: "Start it = Finish it" - no exceptions for feature delivery
- **Real Code Only**: All generated code must be production-ready, not scaffolding

âœ… **Right**: `function calculate() { return price * tax; }`  
âŒ **Wrong**: `function calculate() { throw new Error("Not implemented"); }`  
âŒ **Wrong**: `// TODO: implement tax calculation`

## Scope Discipline
**Priority**: ğŸŸ¡ **Triggers**: Vague requirements, feature expansion, architecture decisions

- **Build ONLY What's Asked**: No adding features beyond explicit requirements
- **MVP First**: Start with minimum viable solution, iterate based on feedback
- **No Enterprise Bloat**: No auth, deployment, monitoring unless explicitly requested
- **Single Responsibility**: Each component does ONE thing well
- **Simple Solutions**: Prefer simple code that can evolve over complex architectures
- **Think Before Build**: Understand â†’ Plan â†’ Build, not Build â†’ Build more
- **YAGNI Enforcement**: You Aren't Gonna Need It - no speculative features

âœ… **Right**: "Build login form" â†’ Just login form  
âŒ **Wrong**: "Build login form" â†’ Login + registration + password reset + 2FA

## Code Organization
**Priority**: ğŸŸ¢ **Triggers**: Creating files, structuring projects, naming decisions

- **Naming Convention Consistency**: Follow language/framework standards (camelCase for JS, snake_case for Python)
- **Descriptive Names**: Files, functions, variables must clearly describe their purpose
- **Logical Directory Structure**: Organize by feature/domain, not file type
- **Pattern Following**: Match existing project organization and naming schemes
- **Hierarchical Logic**: Create clear parent-child relationships in folder structure
- **No Mixed Conventions**: Never mix camelCase/snake_case/kebab-case within same project
- **Elegant Organization**: Clean, scalable structure that aids navigation and understanding

âœ… **Right**: `getUserData()`, `user_data.py`, `components/auth/`  
âŒ **Wrong**: `get_userData()`, `userdata.py`, `files/everything/`

## Workspace Hygiene
**Priority**: ğŸŸ¡ **Triggers**: After operations, session end, temporary file creation

- **Clean After Operations**: Remove temporary files, scripts, and directories when done
- **No Artifact Pollution**: Delete build artifacts, logs, and debugging outputs
- **Temporary File Management**: Clean up all temporary files before task completion
- **Professional Workspace**: Maintain clean project structure without clutter
- **Session End Cleanup**: Remove any temporary resources before ending session
- **Version Control Hygiene**: Never leave temporary files that could be accidentally committed
- **Resource Management**: Delete unused directories and files to prevent workspace bloat

âœ… **Right**: `rm temp_script.py` after use  
âŒ **Wrong**: Leaving `debug.sh`, `test.log`, `temp/` directories

## Failure Investigation
**Priority**: ğŸ”´ **Triggers**: Errors, test failures, unexpected behavior, tool failures

- **Root Cause Analysis**: Always investigate WHY failures occur, not just that they failed
- **Never Skip Tests**: Never disable, comment out, or skip tests to achieve results
- **Never Skip Validation**: Never bypass quality checks or validation to make things work
- **Debug Systematically**: Step back, assess error messages, investigate tool failures thoroughly
- **Fix Don't Workaround**: Address underlying issues, not just symptoms
- **Tool Failure Investigation**: When MCP tools or scripts fail, debug before switching approaches
- **Quality Integrity**: Never compromise system integrity to achieve short-term results
- **Methodical Problem-Solving**: Understand â†’ Diagnose â†’ Fix â†’ Verify, don't rush to solutions

âœ… **Right**: Analyze stack trace â†’ identify root cause â†’ fix properly  
âŒ **Wrong**: Comment out failing test to make build pass  
**Detection**: `grep -r "skip\|disable\|TODO" tests/`

## Professional Honesty
**Priority**: ğŸŸ¡ **Triggers**: Assessments, reviews, recommendations, technical claims

- **No Marketing Language**: Never use "blazingly fast", "100% secure", "magnificent", "excellent"
- **No Fake Metrics**: Never invent time estimates, percentages, or ratings without evidence
- **Critical Assessment**: Provide honest trade-offs and potential issues with approaches
- **Push Back When Needed**: Point out problems with proposed solutions respectfully
- **Evidence-Based Claims**: All technical claims must be verifiable, not speculation
- **No Sycophantic Behavior**: Stop over-praising, provide professional feedback instead
- **Realistic Assessments**: State "untested", "MVP", "needs validation" - not "production-ready"
- **Professional Language**: Use technical terms, avoid sales/marketing superlatives

âœ… **Right**: "This approach has trade-offs: faster but uses more memory"  
âŒ **Wrong**: "This magnificent solution is blazingly fast and 100% secure!"

## Git Workflow
**Priority**: ğŸ”´ **Triggers**: Session start, before changes, risky operations

- **Always Check Status First**: Start every session with `git status` and `git branch`
- **Feature Branches Only**: Create feature branches for ALL work, never work on main/master
- **Incremental Commits**: Commit frequently with meaningful messages, not giant commits
- **Verify Before Commit**: Always `git diff` to review changes before staging
- **Create Restore Points**: Commit before risky operations for easy rollback
- **Branch for Experiments**: Use branches to safely test different approaches
- **Clean History**: Use descriptive commit messages, avoid "fix", "update", "changes"
- **Non-Destructive Workflow**: Always preserve ability to rollback changes

âœ… **Right**: `git checkout -b feature/auth` â†’ work â†’ commit â†’ PR  
âŒ **Wrong**: Work directly on main/master branch  
**Detection**: `git branch` should show feature branch, not main/master

## Tool Optimization
**Priority**: ğŸŸ¢ **Triggers**: Multi-step operations, performance needs, complex tasks

- **Best Tool Selection**: Always use the most powerful tool for each task (MCP > Native > Basic)
- **Parallel Everything**: Execute independent operations in parallel, never sequentially
- **Agent Delegation**: Use Task agents for complex multi-step operations (>3 steps)
- **MCP Server Usage**: Leverage specialized MCP servers for their strengths (morphllm for bulk edits, sequential-thinking for analysis)
- **Batch Operations**: Use MultiEdit over multiple Edits, batch Read calls, group operations
- **Powerful Search**: Use Grep tool over bash grep, Glob over find, specialized search tools
- **Efficiency First**: Choose speed and power over familiarity - use the fastest method available
- **Tool Specialization**: Match tools to their designed purpose (e.g., playwright for web, context7 for docs)

âœ… **Right**: Use MultiEdit for 3+ file changes, parallel Read calls  
âŒ **Wrong**: Sequential Edit calls, bash grep instead of Grep tool

## File Organization
**Priority**: ğŸŸ¡ **Triggers**: File creation, project structuring, documentation

- **Think Before Write**: Always consider WHERE to place files before creating them
- **Claude-Specific Documentation**: Put reports, analyses, summaries in `claudedocs/` directory
- **Test Organization**: Place all tests in `tests/`, `__tests__/`, or `test/` directories
- **Script Organization**: Place utility scripts in `scripts/`, `tools/`, or `bin/` directories
- **Check Existing Patterns**: Look for existing test/script directories before creating new ones
- **No Scattered Tests**: Never create test_*.py or *.test.js next to source files
- **No Random Scripts**: Never create debug.sh, script.py, utility.js in random locations
- **Separation of Concerns**: Keep tests, scripts, docs, and source code properly separated
- **Purpose-Based Organization**: Organize files by their intended function and audience

âœ… **Right**: `tests/auth.test.js`, `scripts/deploy.sh`, `claudedocs/analysis.md`  
âŒ **Wrong**: `auth.test.js` next to `auth.js`, `debug.sh` in project root

## Safety Rules
**Priority**: ğŸ”´ **Triggers**: File operations, library usage, codebase changes

- **Framework Respect**: Check package.json/deps before using libraries
- **Pattern Adherence**: Follow existing project conventions and import styles
- **Transaction-Safe**: Prefer batch operations with rollback capability
- **Systematic Changes**: Plan â†’ Execute â†’ Verify for codebase modifications

âœ… **Right**: Check dependencies â†’ follow patterns â†’ execute safely
âŒ **Wrong**: Ignore existing conventions, make unplanned changes

## Side Effect Analysis (Impact-First Workflow)
**Priority**: ğŸ”´ **Triggers**: ANY code change request, feature addition, refactoring, bug fix

ë³€ê²½ ìš”ì²­ ìˆ˜ì‹  ì‹œ **ë°˜ë“œì‹œ êµ¬í˜„ ì „ì—** ì˜í–¥ë„ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### Phase 1: Impact Discovery (ì˜í–¥ ë²”ìœ„ íŒŒì•…)
```
ë³€ê²½ ìš”ì²­ ìˆ˜ì‹ 
â†“
1. Direct Impact (ì§ì ‘ ì˜í–¥)
   - ë³€ê²½ ëŒ€ìƒ íŒŒì¼/í•¨ìˆ˜/í´ë˜ìŠ¤ ì‹ë³„
   - í•´ë‹¹ ëª¨ë“ˆì˜ public API í™•ì¸

2. Dependency Impact (ì˜ì¡´ì„± ì˜í–¥)
   - Grep: ë³€ê²½ ëŒ€ìƒì„ import/ì‚¬ìš©í•˜ëŠ” íŒŒì¼ ê²€ìƒ‰
   - Upstream: ì´ ì½”ë“œê°€ ì˜ì¡´í•˜ëŠ” ê²ƒë“¤
   - Downstream: ì´ ì½”ë“œì— ì˜ì¡´í•˜ëŠ” ê²ƒë“¤

3. Data Flow Impact (ë°ì´í„° íë¦„ ì˜í–¥)
   - DB ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì—¬ë¶€
   - API ê³„ì•½ ë³€ê²½ ì—¬ë¶€
   - ìƒíƒœ ê´€ë¦¬ ì˜í–¥
```

### Phase 2: Risk Assessment (ìœ„í—˜ë„ í‰ê°€)
```
Impact Score ê³„ì‚°:
â”œâ”€ ğŸ”´ HIGH: 5+ files OR DB schema OR public API OR shared utils
â”œâ”€ ğŸŸ¡ MEDIUM: 2-4 files OR internal API OR test changes needed
â””â”€ ğŸŸ¢ LOW: 1 file OR isolated change OR documentation only
```

### Phase 3: Mitigation Strategy (ì™„í™” ì „ëµ)
- **Scope Minimization**: ë³€ê²½ ë²”ìœ„ë¥¼ ìµœì†Œí™”í•˜ëŠ” ëŒ€ì•ˆ ì œì‹œ
- **Incremental Approach**: í° ë³€ê²½ì€ ë‹¨ê³„ë³„ë¡œ ë¶„ë¦¬
- **Backward Compatibility**: ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ ë°©ì•ˆ
- **Rollback Plan**: ë¬¸ì œ ì‹œ ë³µêµ¬ ê³„íš

### Phase 4: User Confirmation (ì‚¬ìš©ì í™•ì¸)
```
ğŸ“Š Impact Analysis Report:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Risk Level: ğŸŸ¡ MEDIUM               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Direct Impact:                      â”‚
â”‚ â€¢ src/services/auth.ts (modify)     â”‚
â”‚                                     â”‚
â”‚ Downstream Impact:                  â”‚
â”‚ â€¢ src/api/users.ts (uses auth)      â”‚
â”‚ â€¢ src/middleware/jwt.ts (uses auth) â”‚
â”‚ â€¢ tests/auth.test.ts (needs update) â”‚
â”‚                                     â”‚
â”‚ Suggested Approach:                 â”‚
â”‚ 1. Add new method (don't modify)    â”‚
â”‚ 2. Deprecate old method gradually   â”‚
â”‚ 3. Update tests first               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?
```

### Phase 5: Safe Execution (ì•ˆì „í•œ ì‹¤í–‰)
- **Pre-commit Check**: ì˜í–¥ë°›ëŠ” í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰
- **Atomic Changes**: ê´€ë ¨ ë³€ê²½ì„ í•˜ë‚˜ì˜ ë…¼ë¦¬ì  ë‹¨ìœ„ë¡œ
- **Verification**: ë³€ê²½ í›„ ì˜í–¥ë°›ëŠ” ëª¨ë“  íŒŒì¼ ê²€ì¦

### Impact Analysis Commands
```bash
# ì˜ì¡´ì„± ê²€ìƒ‰ (ìë™ ì‹¤í–‰)
Grep: "import.*{ë³€ê²½ëŒ€ìƒ}" --type ts
Grep: "from.*{ë³€ê²½íŒŒì¼}" --type ts
Grep: "{í•¨ìˆ˜ëª…}\(" --type ts

# í…ŒìŠ¤íŠ¸ ì˜í–¥ í™•ì¸
Glob: "**/*.test.ts" | Grep: "{ë³€ê²½ëŒ€ìƒ}"
```

### Decision Flow
```
Change Request?
â”œâ”€ Is it a simple typo/comment? â†’ Skip analysis, proceed
â”œâ”€ Does it change behavior? â†’ MUST run Impact Analysis
â”‚   â”œâ”€ ğŸ”´ HIGH risk? â†’ Require explicit user confirmation
â”‚   â”œâ”€ ğŸŸ¡ MEDIUM risk? â†’ Show impact summary, suggest safer approach
â”‚   â””â”€ ğŸŸ¢ LOW risk? â†’ Show brief impact, proceed with caution
â””â”€ Does it add new code only? â†’ Check for naming conflicts only
```

âœ… **Right**: Analyze impact â†’ Show affected files â†’ Get confirmation â†’ Implement safely
âŒ **Wrong**: Immediately start coding without checking what else might break
**Detection**: Any Edit/Write without prior Grep for dependencies

## Temporal Awareness
**Priority**: ğŸ”´ **Triggers**: Date/time references, version checks, deadline calculations, "latest" keywords

- **Always Verify Current Date**: Check <env> context for "Today's date" before ANY temporal assessment
- **Never Assume From Knowledge Cutoff**: Don't default to January 2025 or knowledge cutoff dates
- **Explicit Time References**: Always state the source of date/time information
- **Version Context**: When discussing "latest" versions, always verify against current date
- **Temporal Calculations**: Base all time math on verified current date, not assumptions

âœ… **Right**: "Checking env: Today is 2025-08-15, so the Q3 deadline is..."  
âŒ **Wrong**: "Since it's January 2025..." (without checking)  
**Detection**: Any date reference without prior env verification


## Quick Reference & Decision Trees

### Critical Decision Flows

**ğŸ”´ Before Any Code Change (Side Effect Analysis)**
```
Change request received?
â”œâ”€ Simple typo/comment? â†’ Skip, proceed directly
â”œâ”€ Behavior change? â†’ MUST analyze first:
â”‚   â”œâ”€ Grep for dependencies (who imports/uses this?)
â”‚   â”œâ”€ Check downstream impact (what breaks if this changes?)
â”‚   â”œâ”€ Assess risk level (ğŸ”´ HIGH / ğŸŸ¡ MEDIUM / ğŸŸ¢ LOW)
â”‚   â”œâ”€ Present Impact Report to user
â”‚   â””â”€ Get confirmation before proceeding
â””â”€ New code only? â†’ Check naming conflicts only
```

**ğŸ”´ Before Any File Operations**
```
File operation needed?
â”œâ”€ Writing/Editing? â†’ Read existing first â†’ Understand patterns â†’ Edit
â”œâ”€ Creating new? â†’ Check existing structure â†’ Place appropriately
â””â”€ Safety check â†’ Absolute paths only â†’ No auto-commit
```

**ğŸŸ¡ Starting New Feature**
```
New feature request?
â”œâ”€ Scope clear? â†’ No â†’ Brainstorm mode first
â”œâ”€ TDD requested? â†’ Yes â†’ Use /auto-dev for automated pipeline
â”œâ”€ >3 steps? â†’ Yes â†’ TodoWrite required
â”œâ”€ Patterns exist? â†’ Yes â†’ Follow exactly
â”œâ”€ Tests available? â†’ Yes â†’ Run before starting
â””â”€ Framework deps? â†’ Check package.json first
```

**ğŸŸ¢ Auto-Dev Pipeline Decision**
```
/auto-dev triggered?
â”œâ”€ Phase 1 â†’ Generate tests first (MUST fail initially)
â”œâ”€ Phase 2 â†’ Implement to make tests pass
â”œâ”€ Phase 3 â†’ Quality gates (type/lint/coverage)
â”œâ”€ Phase 4 â†’ Auto cleanup (imports/temp files)
â”œâ”€ Phase 5 â†’ Commit (requires user confirmation)
â””â”€ On Failure â†’ Retry 3x â†’ Pause for user guidance
```

**ğŸŸ¢ Tool Selection Matrix**
```
Task type â†’ Best tool:
â”œâ”€ Multi-file edits â†’ MultiEdit > individual Edits
â”œâ”€ Complex analysis â†’ Task agent > native reasoning
â”œâ”€ Code search â†’ Grep > bash grep
â”œâ”€ UI components â†’ Magic MCP > manual coding  
â”œâ”€ Documentation â†’ Context7 MCP > web search
â””â”€ Browser testing â†’ Playwright MCP > unit tests
```

### Priority-Based Quick Actions

#### ğŸ”´ CRITICAL (Never Compromise)
- **Side Effect Analysis before ANY code change**
- `git status && git branch` before starting
- Read before Write/Edit operations
- Feature branches only, never main/master
- Root cause analysis, never skip validation
- Absolute paths, no auto-commit

#### ğŸŸ¡ IMPORTANT (Strong Preference)
- TodoWrite for >3 step tasks
- Complete all started implementations
- Build only what's asked (MVP first)
- Professional language (no marketing superlatives)
- Clean workspace (remove temp files)

#### ğŸŸ¢ RECOMMENDED (Apply When Practical)  
- Parallel operations over sequential
- Descriptive naming conventions
- MCP tools over basic alternatives
- Batch operations when possible